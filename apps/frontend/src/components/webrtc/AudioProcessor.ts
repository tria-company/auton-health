// AudioProcessor.ts - Captura e processa Ã¡udio para transcriÃ§Ã£o
// Baseado no audioProcessor.js funcional

export class AudioProcessor {
  private audioContext: AudioContext | null = null;
  private sourceNode: MediaStreamAudioSourceNode | null = null;
  private processorNode: ScriptProcessorNode | AudioWorkletNode | null = null; // âœ… Suporta ambos (moderno e fallback)
  private isProcessing: boolean = false;
  private audioStream: MediaStream | null = null;
  private useAudioWorklet: boolean = false; // âœ… Flag para usar AudioWorklet quando disponÃ­vel

  // ConfiguraÃ§Ãµes de Ã¡udio
  private readonly SAMPLE_RATE = 24000; // OpenAI espera 24kHz
  private readonly BUFFER_SIZE = 4096; // Tamanho do buffer de processamento

  /**
   * Inicializa o processamento de Ã¡udio
   */
  async init(stream: MediaStream): Promise<boolean> {
    console.log('Inicializando AudioProcessor...');

    try {
      // Criar AudioContext
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: this.SAMPLE_RATE
      });

      console.log(`AudioContext criado com sample rate: ${this.audioContext.sampleRate}Hz`);

      // Extrair apenas o Ã¡udio do stream
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length === 0) {
        throw new Error('Nenhuma track de Ã¡udio encontrada');
      }

      this.audioStream = new MediaStream([audioTracks[0]]);

      // Criar source node do stream
      this.sourceNode = this.audioContext.createMediaStreamSource(this.audioStream);

      // âœ… NOVO: Tentar usar AudioWorklet (API moderna) primeiro, com fallback para ScriptProcessorNode
      if (this.audioContext.audioWorklet) {
        try {
          console.log('ðŸ”„ [AudioProcessor] Tentando carregar AudioWorklet (API moderna)...');
          await this.audioContext.audioWorklet.addModule('/worklets/transcription-audio-processor.js');

          // Criar AudioWorkletNode
          this.processorNode = new AudioWorkletNode(this.audioContext, 'transcription-audio-processor');
          this.useAudioWorklet = true;

          // âœ… CORREÃ‡ÃƒO: Conectar ao AnalyserNode (nÃ£o reproduz Ã¡udio)
          const analyser = this.audioContext.createAnalyser();
          analyser.fftSize = 256;

          this.sourceNode.connect(this.processorNode);
          this.processorNode.connect(analyser);

          console.log('âœ… AudioProcessor: AudioWorkletNode conectado (API moderna, sem reproduÃ§Ã£o de Ã¡udio)');
        } catch (workletError) {
          console.warn('âš ï¸ [AudioProcessor] AudioWorklet nÃ£o disponÃ­vel, usando ScriptProcessorNode (fallback):', workletError);
          this.useAudioWorklet = false;
        }
      } else {
        console.warn('âš ï¸ [AudioProcessor] AudioWorklet nÃ£o suportado neste navegador, usando ScriptProcessorNode (fallback)');
        this.useAudioWorklet = false;
      }

      // âœ… FALLBACK: Usar ScriptProcessorNode se AudioWorklet nÃ£o estiver disponÃ­vel
      if (!this.useAudioWorklet) {
        this.processorNode = this.audioContext.createScriptProcessor(
          this.BUFFER_SIZE,
          1, // 1 canal de entrada (mono)
          1  // 1 canal de saÃ­da
        );

        // âœ… CORREÃ‡ÃƒO CRÃTICA: Usar GainNode com gain 0 conectado ao destination
        // Isso permite que o ScriptProcessorNode funcione corretamente sem reproduzir Ã¡udio
        const silentGain = this.audioContext.createGain();
        silentGain.gain.value = 0; // Silencioso - processa mas nÃ£o reproduz

        // Conectar nodes: source -> processor -> silentGain -> destination
        this.sourceNode.connect(this.processorNode);
        this.processorNode.connect(silentGain);
        silentGain.connect(this.audioContext.destination);

        console.log('âœ… AudioProcessor: ScriptProcessorNode conectado via GainNode silencioso (gain=0) [FALLBACK]');
      }

      console.log('âœ… AudioProcessor inicializado');
      return true;

    } catch (error) {
      console.error('Erro ao inicializar AudioProcessor:', error);
      return false;
    }
  }

  /**
   * Substitui a track de Ã¡udio sendo processada (Hot Swapping)
   */
  async replaceTrack(newTrack: MediaStreamTrack): Promise<void> {
    if (!this.audioContext || !this.processorNode) {
      throw new Error('AudioProcessor nÃ£o inicializado');
    }

    console.log('ðŸ”„ [AudioProcessor] Substituindo track de Ã¡udio...');

    // 1. Parar track antiga e desconectar source antigo
    if (this.audioStream) {
      this.audioStream.getTracks().forEach(t => t.stop());
    }
    if (this.sourceNode) {
      this.sourceNode.disconnect();
    }

    // 2. Criar novo stream e source
    this.audioStream = new MediaStream([newTrack]);
    this.sourceNode = this.audioContext.createMediaStreamSource(this.audioStream);

    // 3. Reconectar ao processor (mantendo o restante da chain intacto)
    if (this.processorNode) {
      this.sourceNode.connect(this.processorNode);
    }

    console.log('âœ… [AudioProcessor] Track substituÃ­da com sucesso');
  }

  /**
   * Inicia o processamento e envio de Ã¡udio
   */
  start(onAudioData: (audioBase64: string) => void): boolean {
    if (!this.processorNode) {
      console.warn('ProcessorNode nÃ£o inicializado');
      return false;
    }

    console.log(`â–¶ï¸ Iniciando processamento de Ã¡udio (${this.useAudioWorklet ? 'AudioWorklet' : 'ScriptProcessorNode'})...`);
    this.isProcessing = true;

    // âœ… NOVO: Handler diferente para AudioWorklet vs ScriptProcessorNode
    if (this.useAudioWorklet && this.processorNode instanceof AudioWorkletNode) {
      // AudioWorklet usa MessagePort para comunicaÃ§Ã£o
      this.processorNode.port.onmessage = (event) => {
        if (!this.isProcessing) return;

        const { type, audioData } = event.data;

        if (type === 'audiodata' && audioData) {
          // Converter Array para Float32Array
          const float32Data = new Float32Array(audioData);

          // Resample se necessÃ¡rio (usar sampleRate do AudioContext)
          let processedData = float32Data;
          if (this.audioContext && this.audioContext.sampleRate !== this.SAMPLE_RATE) {
            processedData = this.resampleAudio(
              float32Data,
              this.audioContext.sampleRate,
              this.SAMPLE_RATE
            );
          }

          // Converter para base64
          const base64Audio = this.audioToBase64(processedData);

          // Callback com os dados
          if (onAudioData && typeof onAudioData === 'function') {
            onAudioData(base64Audio);
          }
        }
      };
    } else {
      // âœ… FALLBACK: ScriptProcessorNode usa onaudioprocess
      (this.processorNode as ScriptProcessorNode).onaudioprocess = (audioEvent) => {
        if (!this.isProcessing) return;

        // Pegar dados de Ã¡udio do buffer de entrada
        const inputData = audioEvent.inputBuffer.getChannelData(0);

        // Resample se necessÃ¡rio (do sample rate do AudioContext para 24kHz)
        let audioData: any = inputData;
        if (this.audioContext && this.audioContext.sampleRate !== this.SAMPLE_RATE) {
          audioData = this.resampleAudio(
            inputData,
            this.audioContext.sampleRate,
            this.SAMPLE_RATE
          );
        }

        // Converter para base64
        const base64Audio = this.audioToBase64(audioData);

        // Callback com os dados
        if (onAudioData && typeof onAudioData === 'function') {
          onAudioData(base64Audio);
        }
      };
    }

    console.log('âœ… Processamento ativo');
    return true;
  }

  /**
   * Para o processamento de Ã¡udio
   */
  stop(): void {
    console.log('â¸ï¸ Parando processamento de Ã¡udio...');
    this.isProcessing = false;

    if (this.processorNode) {
      if (this.useAudioWorklet && this.processorNode instanceof AudioWorkletNode) {
        // AudioWorklet: limpar MessagePort
        this.processorNode.port.onmessage = null;
      } else {
        // ScriptProcessorNode: limpar onaudioprocess
        (this.processorNode as ScriptProcessorNode).onaudioprocess = null;
      }
    }
  }

  /**
   * Limpa recursos
   */
  cleanup(): void {
    console.log('Limpando AudioProcessor...');

    this.stop();

    if (this.sourceNode) {
      this.sourceNode.disconnect();
      this.sourceNode = null;
    }

    if (this.processorNode) {
      this.processorNode.disconnect();
      this.processorNode = null;
    }

    if (this.audioContext && this.audioContext.state !== 'closed') {
      this.audioContext.close();
      this.audioContext = null;
    }

    if (this.audioStream) {
      this.audioStream.getTracks().forEach(track => track.stop());
      this.audioStream = null;
    }

    console.log('âœ… AudioProcessor limpo');
  }

  /**
   * Retorna o estado atual
   */
  getStatus() {
    return {
      initialized: this.audioContext !== null,
      processing: this.isProcessing,
      sampleRate: this.audioContext?.sampleRate || 0
    };
  }

  /**
   * Converte Float32Array para PCM16 (formato esperado pela OpenAI)
   */
  private convertFloat32ToPCM16(float32Array: Float32Array): Int16Array {
    const pcm16 = new Int16Array(float32Array.length);

    for (let i = 0; i < float32Array.length; i++) {
      // Clamp o valor entre -1 e 1
      let sample = Math.max(-1, Math.min(1, float32Array[i]));

      // Converter para 16-bit integer
      pcm16[i] = sample < 0
        ? sample * 0x8000  // -32768
        : sample * 0x7FFF; // 32767
    }

    return pcm16;
  }

  /**
   * Converte PCM16 para Base64 (formato de envio para OpenAI)
   */
  private pcm16ToBase64(pcm16Array: Int16Array): string {
    // Converter Int16Array para Uint8Array (bytes)
    const uint8Array = new Uint8Array(pcm16Array.buffer as ArrayBuffer);

    // Converter para string binÃ¡ria
    let binary = '';
    const len = uint8Array.byteLength;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(uint8Array[i]);
    }

    // Converter para Base64
    return btoa(binary);
  }

  /**
   * Converte Float32 diretamente para Base64
   */
  private audioToBase64(float32Array: Float32Array): string {
    const pcm16 = this.convertFloat32ToPCM16(float32Array);
    return this.pcm16ToBase64(pcm16);
  }

  /**
   * Resample Ã¡udio de uma sample rate para outra (se necessÃ¡rio)
   */
  private resampleAudio(audioData: any, fromRate: number, toRate: number): Float32Array {
    if (fromRate === toRate) return new Float32Array(audioData);

    const ratio = fromRate / toRate;
    const newLength = Math.round(audioData.length / ratio);
    const result = new Float32Array(newLength);

    for (let i = 0; i < newLength; i++) {
      const srcIndex = i * ratio;
      const srcIndexFloor = Math.floor(srcIndex);
      const srcIndexCeil = Math.min(srcIndexFloor + 1, audioData.length - 1);
      const t = srcIndex - srcIndexFloor;

      // InterpolaÃ§Ã£o linear
      result[i] = audioData[srcIndexFloor] * (1 - t) + audioData[srcIndexCeil] * t;
    }

    return result;
  }
}
